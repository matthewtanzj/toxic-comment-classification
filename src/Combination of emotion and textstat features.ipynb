{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textstat.textstat import textstat\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the liblinear path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing sklearn libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\serena\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\Users\\serena\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stating the path of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"../data/data/train.csv\"\n",
    "test_path = \"../data/data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_lexicon_path = \"../data/features/NRC-AffectIntensity-Lexicon.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_comment(comment): # cleaning to be filled up\n",
    "    if math.isnan(comment):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return str(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textstat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_syllable(comment):\n",
    "    comment_lst = comment.split(\" \")\n",
    "    syllable_count = []\n",
    "    for word in comment_lst:\n",
    "        try:\n",
    "            syllable_count.extend([textstat.syllable_count(word)])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(syllable_count) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.average(syllable_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Translator to remove all puncutuations "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* I did not remove all the punctuations at the data cleaning stage because: \n",
    "    - some of the puncutuations may be useful (ie, emoticons / intensifiers like ?!?!?!?) \n",
    "  \n",
    "  hence, these can be captured during feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the average emotion score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_emotion(comment, dict_):\n",
    "    try:\n",
    "        comment = comment.translate(translator)\n",
    "    except:\n",
    "        comment = \"\"\n",
    "    comment_lst = comment.split(\" \")\n",
    "    score_lst = [dict_.get(word.lower()) for word in comment_lst if dict_.get(word.lower()) is not None]\n",
    "    if len(score_lst) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.average(score_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data File Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFile:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.__path = path\n",
    "        df = pd.read_csv(path).replace(np.nan, '', regex=True)\n",
    "        self.__df = df\n",
    "        \n",
    "    def dataCleaning(self):\n",
    "        self.__df.loc[:, \"comment_text\"] = self.__df.loc[:, \"comment_text\"].apply(lambda x : clean_comment(x) )\n",
    "    \n",
    "    def getDF(self):\n",
    "        return self.__df\n",
    "    \n",
    "    def updateDF(self, new_df):\n",
    "        self.__df = new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeaturesEngineer:\n",
    "    \n",
    "    def __init__(self, emotion_lexicon_path):\n",
    "        self.emotion_lexicon_path = emotion_lexicon_path\n",
    "        self.emotion_lexicon = pd.read_csv(self.emotion_lexicon_path, sep = \"\\t\")\n",
    "        \n",
    "        self.anger = self.emotion_lexicon.loc[self.emotion_lexicon.loc[:, \"AffectDimension\"] == \"anger\", :]\n",
    "        self.fear = self.emotion_lexicon.loc[self.emotion_lexicon.loc[:, \"AffectDimension\"] == \"fear\", :]\n",
    "        self.joy = self.emotion_lexicon.loc[self.emotion_lexicon.loc[:, \"AffectDimension\"] == \"joy\", :]\n",
    "        self.sadness = self.emotion_lexicon.loc[self.emotion_lexicon.loc[:, \"AffectDimension\"] == \"sadness\", :]\n",
    "        \n",
    "        anger_dict = {}\n",
    "        for i in range(0, self.anger.shape[0]):\n",
    "            word = self.anger.iloc[i, :].term\n",
    "            score = self.anger.iloc[i, :].score\n",
    "            anger_dict[word] = score\n",
    "            \n",
    "        fear_dict = {}\n",
    "        for i in range(0, self.fear.shape[0]):\n",
    "            word = self.fear.iloc[i, :].term\n",
    "            score = self.fear.iloc[i, :].score\n",
    "            fear_dict[word] = score\n",
    "            \n",
    "        joy_dict = {}\n",
    "        for i in range(0, self.joy.shape[0]):\n",
    "            word = self.joy.iloc[i, :].term\n",
    "            score = self.joy.iloc[i, :].score\n",
    "            joy_dict[word] = score\n",
    "            \n",
    "        sadness_dict = {}\n",
    "        for i in range(0, self.sadness.shape[0]):\n",
    "            word = self.sadness.iloc[i, :].term\n",
    "            score = self.sadness.iloc[i, :].score\n",
    "            sadness_dict[word] = score\n",
    "            \n",
    "        self.anger_dict = anger_dict\n",
    "        self.fear_dict = fear_dict\n",
    "        self.joy_dict = joy_dict\n",
    "        self.sadness_dict = sadness_dict\n",
    "    \n",
    "    def createTextStatFeatures(self, df):\n",
    "        \n",
    "        df.loc[:,'comment_len'] = df.loc[:,'comment_text'].apply(lambda x: len(x))\n",
    "        df.loc[:,'comment_avg_syllable'] = df.loc[:,'comment_text'].apply(lambda x: average_syllable(x))\n",
    "        df.loc[:,'comment_syllable'] = df.loc[:,'comment_text'].apply(lambda x: textstat.syllable_count(x))\n",
    "        df.loc[:,'comment_num_sent'] = df.loc[:, 'comment_text'].apply(lambda x: textstat.sentence_count(x))\n",
    "        df.loc[:, \"comment_word_per_sent\"] = df.loc[:, \"comment_text\"].apply(lambda x: textstat.lexicon_count(x) / textstat.sentence_count(x))\n",
    "        df.loc[:,'comment_flesch_reading_ease'] = df.loc[:,'comment_text'].apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "        df.loc[:,'comment_flesch_kincaid_grade'] = df.loc[:,'comment_text'].apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def createEmotionFeatures(self, df):\n",
    "        \n",
    "        df.loc[:, \"avg_anger\"] = df.loc[:, \"comment_text\"].apply(lambda x: avg_emotion(x, self.anger_dict))\n",
    "        df.loc[:, \"avg_fear\"] = df.loc[:, \"comment_text\"].apply(lambda x: avg_emotion(x, self.fear_dict))\n",
    "        df.loc[:, \"avg_joy\"] = df.loc[:, \"comment_text\"].apply(lambda x: avg_emotion(x, self.joy_dict))\n",
    "        df.loc[:, \"avg_sadness\"] = df.loc[:, \"comment_text\"].apply(lambda x: avg_emotion(x, self.sadness_dict))\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(y_label, y_proba):\n",
    "    return log_loss(y_label, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get the engineered features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_manual_features(df):\n",
    "    \n",
    "    col = [\"id\", \"comment_text\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\" ]\n",
    "    df_sieved = df.drop(col, axis = 1)\n",
    "    \n",
    "    return df_sieved\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning to FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_manual_features_ft = FunctionTransformer(get_manual_features, validate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do grid search for the best C "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data in nr-fold cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(num, cv):\n",
    "    \n",
    "    num_points = int(num/cv)\n",
    "    num_points_last = num - (cv-1) * num_points\n",
    "    selected = []\n",
    "    index_test = []\n",
    "    index_train = []\n",
    "    \n",
    "    for i in range(0, cv):\n",
    "        if i == cv-1:\n",
    "            choices = [x for x in range(0, num) if x not in selected]\n",
    "            picks = random.sample(choices, num_points_last)\n",
    "            remaining = [x for x in range(0, num) if x not in picks]\n",
    "            index_test.append(picks)\n",
    "            index_train.append(remaining)\n",
    "            selected.extend(picks)\n",
    "        else:\n",
    "            choices = [x for x in range(0, num) if x not in selected]\n",
    "            picks = random.sample(choices, num_points)\n",
    "            remaining = [x for x in range(0, num) if x not in picks]\n",
    "            index_test.append(picks)\n",
    "            index_train.append(remaining)\n",
    "            selected.extend(picks)\n",
    "            \n",
    "    return index_train, index_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_C(min_c, max_c, step, data, label, cv):\n",
    "    index_train, index_test = split_data(data.shape[0], cv)\n",
    "    c_range = np.arange(min_c, max_c, step)\n",
    "    loss_lst_compiled = []\n",
    "    for c in c_range:\n",
    "        val = 2.0 ** c\n",
    "        logreg = LogisticRegression(solver = \"newton-cg\", C = val)\n",
    "        pipe = Pipeline([\n",
    "            (\"getmanualfeatures\", get_manual_features_ft),\n",
    "            (\"classifier\", logreg)\n",
    "        ])\n",
    "        loss_lst = []\n",
    "        for i in range(0, cv):\n",
    "            test_ = index_test[i]\n",
    "            train_ = index_train[i]\n",
    "            \n",
    "            features_train = data.iloc[train_, :]\n",
    "            labels_train = data.iloc[train_, :].loc[:, label]\n",
    "            \n",
    "            features_test = data.iloc[test_, :]\n",
    "            labels_test = data.iloc[test_, :].loc[:, label]\n",
    "            \n",
    "            pipe.fit(features_train, labels_train)\n",
    "            labels = pipe.predict(features_test)\n",
    "            proba = pipe.predict_proba(features_test)\n",
    "            \n",
    "            loss = loss_func(labels_test, proba)\n",
    "            loss_lst.extend([loss])\n",
    "        \n",
    "        avg_loss = np.average(loss_lst)\n",
    "        loss_lst_compiled.append(avg_loss)\n",
    "        \n",
    "    loss_lst_compiled = [x for x in zip(c_range, loss_lst_compiled)]  \n",
    "    loss_lst_compiled = sorted(loss_lst_compiled, key= lambda x: x[1])\n",
    "    return  loss_lst_compiled[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    loss_compiled = []\n",
    "    \n",
    "    for label in labels:\n",
    "        best_c, best_rate = best_C(-3,3,1, trainData.getDF(), label, 5)\n",
    "        print('Log loss for \"{}\" based on 5 fold CV: {}, with log2c = {}'.format(label, best_rate, best_c))\n",
    "        loss_compiled.extend([best_rate])\n",
    "    \n",
    "    avg_loss = np.average(loss_compiled)\n",
    "    print('Average Log loss = {}'.format(avg_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading in train data\n",
      "Done creating emotion features for train data\n",
      "Done creating textstat features for train data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    extractor = FeaturesEngineer(emotion_lexicon_path)\n",
    "    trainData = DataFile(path = train_path)\n",
    "    print(\"Done reading in train data\")\n",
    "    #testData = DataFile(path= test_path)\n",
    "    #print(\"Done reading in test data\")\n",
    "    \n",
    "    trainData.updateDF(extractor.createEmotionFeatures(trainData.getDF()))\n",
    "    print(\"Done creating emotion features for train data\")\n",
    "    #testData.updateDF(extractor.createEmotionFeatures(testData.getDF()))\n",
    "    #print(\"Done creating emotion features for test data\")\n",
    "    \n",
    "    trainData.updateDF(extractor.createTextStatFeatures(trainData.getDF()))\n",
    "    print(\"Done creating textstat features for train data\")\n",
    "    #testData.updateDF(extractor.createTextStatFeatures(testData.getDF()))\n",
    "    #print(\"Done creating textstat features for test data\")\n",
    "    \n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
