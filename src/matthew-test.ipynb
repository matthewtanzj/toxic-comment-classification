{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as regex\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95851, 8)\n",
      "(226998, 2)\n"
     ]
    }
   ],
   "source": [
    "trainData = pd.read_csv('../data/data/train.csv', header = 0)\n",
    "testData = pd.read_csv('../data/data/test.csv', header = 0)\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "1  27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "2  54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>==Orphaned non-free media (Image:41cD1jboEvL. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>::Kentuckiana is colloquial.  Even though the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>Hello fellow Wikipedians,\\nI have just modifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>AKC Suspensions \\nThe Morning Call - Feb 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>== [WIKI_LINK: Talk:Celts] ==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text\n",
       "0   6044863  ==Orphaned non-free media (Image:41cD1jboEvL. ...\n",
       "1   6102620  ::Kentuckiana is colloquial.  Even though the ...\n",
       "2  14563293  Hello fellow Wikipedians,\\nI have just modifie...\n",
       "3  21086297  AKC Suspensions \\nThe Morning Call - Feb 24, 2...\n",
       "4  22982444                      == [WIKI_LINK: Talk:Celts] =="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing elements (examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9237\n",
      "965\n",
      "5109\n",
      "305\n",
      "4765\n",
      "814\n"
     ]
    }
   ],
   "source": [
    "print(trainData.loc[trainData.loc[:, \"toxic\"] == 1,].shape[0])\n",
    "print(trainData.loc[trainData.loc[:, \"severe_toxic\"] == 1,].shape[0])\n",
    "print(trainData.loc[trainData.loc[:, \"obscene\"] == 1,].shape[0])\n",
    "print(trainData.loc[trainData.loc[:, \"threat\"] == 1,].shape[0])\n",
    "print(trainData.loc[trainData.loc[:, \"insult\"] == 1,].shape[0])\n",
    "print(trainData.loc[trainData.loc[:, \"identity_hate\"] == 1,].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxicData = trainData.loc[trainData.loc[:, \"toxic\"] == 1,]\n",
    "severeToxicData = trainData.loc[trainData.loc[:, \"severe_toxic\"] == 1,]\n",
    "obsceneData = trainData.loc[trainData.loc[:, \"obscene\"] == 1,]\n",
    "threatData = trainData.loc[trainData.loc[:, \"threat\"] == 1,]\n",
    "insultData = trainData.loc[trainData.loc[:, \"insult\"] == 1,]\n",
    "identityHateData = trainData.loc[trainData.loc[:, \"identity_hate\"] == 1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(max_df=1.0, min_df=0.001, stop_words = ENGLISH_STOP_WORDS, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "vectorizer = TfidfVectorizer(max_df=1.0, min_df=0.001, stop_words = ENGLISH_STOP_WORDS, token_pattern=u'\\\\b[a-zA-Z]\\w+\\\\b')\n",
    "\n",
    "data_corpus = trainData.comment_text\n",
    "X = vectorizer.fit_transform(data_corpus)\n",
    "# get frequencies of words\n",
    "freqs = [(word, X.getcol(idx).sum()) for word, idx in vectorizer.vocabulary_.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.2, min_df=0.01, stop_words = ENGLISH_STOP_WORDS, token_pattern=u'\\\\b[a-zA-Z]\\w+\\\\b')\n",
    "toxicData_corpus = toxicData.comment_text\n",
    "X = vectorizer.fit_transform(data_corpus)\n",
    "freqs = [(word, X.getcol(idx).sum()) for word, idx in vectorizer.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TfidfVectorizer in module sklearn.feature_extraction.text object:\n",
      "\n",
      "class TfidfVectorizer(CountVectorizer)\n",
      " |  Convert a collection of raw documents to a matrix of TF-IDF features.\n",
      " |  \n",
      " |  Equivalent to CountVectorizer followed by TfidfTransformer.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  input : string {'filename', 'file', 'content'}\n",
      " |      If 'filename', the sequence passed as an argument to fit is\n",
      " |      expected to be a list of filenames that need reading to fetch\n",
      " |      the raw content to analyze.\n",
      " |  \n",
      " |      If 'file', the sequence items must have a 'read' method (file-like\n",
      " |      object) that is called to fetch the bytes in memory.\n",
      " |  \n",
      " |      Otherwise the input is expected to be the sequence strings or\n",
      " |      bytes items are expected to be analyzed directly.\n",
      " |  \n",
      " |  encoding : string, 'utf-8' by default.\n",
      " |      If bytes or files are given to analyze, this encoding is used to\n",
      " |      decode.\n",
      " |  \n",
      " |  decode_error : {'strict', 'ignore', 'replace'}\n",
      " |      Instruction on what to do if a byte sequence is given to analyze that\n",
      " |      contains characters not of the given `encoding`. By default, it is\n",
      " |      'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      " |      values are 'ignore' and 'replace'.\n",
      " |  \n",
      " |  strip_accents : {'ascii', 'unicode', None}\n",
      " |      Remove accents during the preprocessing step.\n",
      " |      'ascii' is a fast method that only works on characters that have\n",
      " |      an direct ASCII mapping.\n",
      " |      'unicode' is a slightly slower method that works on any characters.\n",
      " |      None (default) does nothing.\n",
      " |  \n",
      " |  analyzer : string, {'word', 'char'} or callable\n",
      " |      Whether the feature should be made of word or character n-grams.\n",
      " |  \n",
      " |      If a callable is passed it is used to extract the sequence of features\n",
      " |      out of the raw, unprocessed input.\n",
      " |  \n",
      " |  preprocessor : callable or None (default)\n",
      " |      Override the preprocessing (string transformation) stage while\n",
      " |      preserving the tokenizing and n-grams generation steps.\n",
      " |  \n",
      " |  tokenizer : callable or None (default)\n",
      " |      Override the string tokenization step while preserving the\n",
      " |      preprocessing and n-grams generation steps.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |  ngram_range : tuple (min_n, max_n)\n",
      " |      The lower and upper boundary of the range of n-values for different\n",
      " |      n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      " |      will be used.\n",
      " |  \n",
      " |  stop_words : string {'english'}, list, or None (default)\n",
      " |      If a string, it is passed to _check_stop_list and the appropriate stop\n",
      " |      list is returned. 'english' is currently the only supported string\n",
      " |      value.\n",
      " |  \n",
      " |      If a list, that list is assumed to contain stop words, all of which\n",
      " |      will be removed from the resulting tokens.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |      If None, no stop words will be used. max_df can be set to a value\n",
      " |      in the range [0.7, 1.0) to automatically detect and filter stop\n",
      " |      words based on intra corpus document frequency of terms.\n",
      " |  \n",
      " |  lowercase : boolean, default True\n",
      " |      Convert all characters to lowercase before tokenizing.\n",
      " |  \n",
      " |  token_pattern : string\n",
      " |      Regular expression denoting what constitutes a \"token\", only used\n",
      " |      if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
      " |      or more alphanumeric characters (punctuation is completely ignored\n",
      " |      and always treated as a token separator).\n",
      " |  \n",
      " |  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly higher than the given threshold (corpus-specific\n",
      " |      stop words).\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  min_df : float in range [0.0, 1.0] or int, default=1\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly lower than the given threshold. This value is also\n",
      " |      called cut-off in the literature.\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  max_features : int or None, default=None\n",
      " |      If not None, build a vocabulary that only consider the top\n",
      " |      max_features ordered by term frequency across the corpus.\n",
      " |  \n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  vocabulary : Mapping or iterable, optional\n",
      " |      Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      " |      indices in the feature matrix, or an iterable over terms. If not\n",
      " |      given, a vocabulary is determined from the input documents.\n",
      " |  \n",
      " |  binary : boolean, default=False\n",
      " |      If True, all non-zero term counts are set to 1. This does not mean\n",
      " |      outputs will have only 0/1 values, only that the tf term in tf-idf\n",
      " |      is binary. (Set idf and normalization to False to get 0/1 outputs.)\n",
      " |  \n",
      " |  dtype : type, optional\n",
      " |      Type of the matrix returned by fit_transform() or transform().\n",
      " |  \n",
      " |  norm : 'l1', 'l2' or None, optional\n",
      " |      Norm used to normalize term vectors. None for no normalization.\n",
      " |  \n",
      " |  use_idf : boolean, default=True\n",
      " |      Enable inverse-document-frequency reweighting.\n",
      " |  \n",
      " |  smooth_idf : boolean, default=True\n",
      " |      Smooth idf weights by adding one to document frequencies, as if an\n",
      " |      extra document was seen containing every term in the collection\n",
      " |      exactly once. Prevents zero divisions.\n",
      " |  \n",
      " |  sublinear_tf : boolean, default=False\n",
      " |      Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  vocabulary_ : dict\n",
      " |      A mapping of terms to feature indices.\n",
      " |  \n",
      " |  idf_ : array, shape = [n_features], or None\n",
      " |      The learned idf vector (global term weights)\n",
      " |      when ``use_idf`` is set to True, None otherwise.\n",
      " |  \n",
      " |  stop_words_ : set\n",
      " |      Terms that were ignored because they either:\n",
      " |  \n",
      " |        - occurred in too many documents (`max_df`)\n",
      " |        - occurred in too few documents (`min_df`)\n",
      " |        - were cut off by feature selection (`max_features`).\n",
      " |  \n",
      " |      This is only available if no vocabulary was given.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  CountVectorizer\n",
      " |      Tokenize the documents and count the occurrences of token and return\n",
      " |      them as a sparse matrix\n",
      " |  \n",
      " |  TfidfTransformer\n",
      " |      Apply Term Frequency Inverse Document Frequency normalization to a\n",
      " |      sparse matrix of occurrence counts.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The ``stop_words_`` attribute can get large and increase the model size\n",
      " |  when pickling. This attribute is provided only for introspection and can\n",
      " |  be safely removed using delattr or set to None before pickling.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TfidfVectorizer\n",
      " |      CountVectorizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      VectorizerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, raw_documents, y=None)\n",
      " |      Learn vocabulary and idf from training set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          an iterable which yields either str, unicode or file objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : TfidfVectorizer\n",
      " |  \n",
      " |  fit_transform(self, raw_documents, y=None)\n",
      " |      Learn vocabulary and idf, return term-document matrix.\n",
      " |      \n",
      " |      This is equivalent to fit followed by transform, but more efficiently\n",
      " |      implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          an iterable which yields either str, unicode or file objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          Tf-idf-weighted document-term matrix.\n",
      " |  \n",
      " |  transform(self, raw_documents, copy=True)\n",
      " |      Transform documents to document-term matrix.\n",
      " |      \n",
      " |      Uses the vocabulary and document frequencies (df) learned by fit (or\n",
      " |      fit_transform).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          an iterable which yields either str, unicode or file objects\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Whether to copy X and operate on the copy or perform in-place\n",
      " |          operations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          Tf-idf-weighted document-term matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  idf_\n",
      " |  \n",
      " |  norm\n",
      " |  \n",
      " |  smooth_idf\n",
      " |  \n",
      " |  sublinear_tf\n",
      " |  \n",
      " |  use_idf\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from CountVectorizer:\n",
      " |  \n",
      " |  get_feature_names(self)\n",
      " |      Array mapping from feature integer indices to feature name\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Return terms per document with nonzero entries in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array, sparse matrix}, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_inv : list of arrays, len = n_samples\n",
      " |          List of arrays of terms.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from VectorizerMixin:\n",
      " |  \n",
      " |  build_analyzer(self)\n",
      " |      Return a callable that handles preprocessing and tokenization\n",
      " |  \n",
      " |  build_preprocessor(self)\n",
      " |      Return a function to preprocess the text before tokenization\n",
      " |  \n",
      " |  build_tokenizer(self)\n",
      " |      Return a function that splits a string into a sequence of tokens\n",
      " |  \n",
      " |  decode(self, doc)\n",
      " |      Decode the input into a string of unicode symbols\n",
      " |      \n",
      " |      The decoding strategy depends on the vectorizer parameters.\n",
      " |  \n",
      " |  get_stop_words(self)\n",
      " |      Build or fetch the effective stop words list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk', 3847.1784732587298),\n",
       " ('page', 3694.4734956941193),\n",
       " ('wikipedia', 3452.2645737099001),\n",
       " ('just', 2733.3305125751103),\n",
       " ('like', 2613.7208163312648),\n",
       " ('don', 2391.9419358211317),\n",
       " ('think', 2137.7945252462555),\n",
       " ('thanks', 2108.8683777129186),\n",
       " ('know', 2068.6405096617859),\n",
       " ('edit', 1911.8878067744085),\n",
       " ('people', 1800.8652179207747),\n",
       " ('did', 1800.840449898086),\n",
       " ('time', 1638.1105409711299),\n",
       " ('user', 1613.9778685218346),\n",
       " ('articles', 1538.818161248709),\n",
       " ('good', 1527.1192254604891),\n",
       " ('ve', 1510.0793580404272),\n",
       " ('use', 1469.804460955319),\n",
       " ('utc', 1438.1208967267376),\n",
       " ('make', 1378.5761906888872),\n",
       " ('does', 1354.2783952995787),\n",
       " ('thank', 1341.72242750073),\n",
       " ('want', 1303.5374474276689),\n",
       " ('wp', 1287.7830185191094),\n",
       " ('way', 1251.7280468032736),\n",
       " ('section', 1227.3384242287452),\n",
       " ('stop', 1219.229302864939),\n",
       " ('information', 1217.807944693225),\n",
       " ('new', 1213.784822537707),\n",
       " ('editing', 1212.6945328974928),\n",
       " ('say', 1202.0236007768406),\n",
       " ('sources', 1199.3599534508696),\n",
       " ('edits', 1198.3269385533818),\n",
       " ('source', 1184.8310206345161),\n",
       " ('blocked', 1167.182908795942),\n",
       " ('need', 1158.632131612477),\n",
       " ('ll', 1151.4293779758184),\n",
       " ('really', 1139.8806747406902),\n",
       " ('help', 1131.981084717338),\n",
       " ('pages', 1125.5068869370589),\n",
       " ('right', 1123.0863975002533),\n",
       " ('discussion', 1088.1180001009257),\n",
       " ('look', 1070.9553129305723),\n",
       " ('work', 1061.0056623558121),\n",
       " ('read', 1014.1477574906005),\n",
       " ('deletion', 990.56136862710434),\n",
       " ('going', 987.07398077416792),\n",
       " ('used', 983.25160270541051),\n",
       " ('add', 966.29124567376937),\n",
       " ('added', 957.03868084359999),\n",
       " ('said', 954.35132401072167),\n",
       " ('list', 945.08843744460125),\n",
       " ('point', 943.85832745036726),\n",
       " ('fuck', 931.28920465901308),\n",
       " ('link', 922.51982410892833),\n",
       " ('removed', 921.61728407398323),\n",
       " ('image', 914.03406838795399),\n",
       " ('vandalism', 906.33672242951297),\n",
       " ('hi', 905.69008511169125),\n",
       " ('block', 901.11652520582311),\n",
       " ('fact', 895.90070622525332),\n",
       " ('wiki', 886.59090347122833),\n",
       " ('deleted', 880.95042442466922),\n",
       " ('redirect', 878.63387616267505),\n",
       " ('sure', 876.94783238746595),\n",
       " ('sorry', 873.39044884261796),\n",
       " ('better', 865.82546409549354),\n",
       " ('comment', 860.53905967281821),\n",
       " ('history', 848.18262247127643),\n",
       " ('let', 839.54114550220015),\n",
       " ('doesn', 808.55674537040795),\n",
       " ('reason', 803.07971102032616),\n",
       " ('http', 798.73977232429809),\n",
       " ('actually', 793.95794964336778),\n",
       " ('case', 789.51951199440919),\n",
       " ('didn', 776.66702699565394),\n",
       " ('content', 774.45438278597032),\n",
       " ('comments', 750.1126556211384),\n",
       " ('agree', 749.52146354539343),\n",
       " ('wrong', 749.01323752991982),\n",
       " ('change', 746.09514470698855),\n",
       " ('editors', 744.40129336728421),\n",
       " ('personal', 736.08377348520605),\n",
       " ('yes', 731.73017014859488),\n",
       " ('little', 731.69492949665357),\n",
       " ('believe', 728.77823720606409),\n",
       " ('thing', 726.22943100268537),\n",
       " ('place', 722.77370746403801),\n",
       " ('welcome', 722.49366335387583),\n",
       " ('question', 720.94864903740893),\n",
       " ('problem', 712.71907134411288),\n",
       " ('continue', 711.83722202738454),\n",
       " ('note', 704.18407341168177),\n",
       " ('person', 703.68189456618597),\n",
       " ('hope', 696.6807938953657),\n",
       " ('com', 696.32297834085955),\n",
       " ('things', 692.14338976973636),\n",
       " ('best', 687.36415795274513),\n",
       " ('feel', 679.6615228931156),\n",
       " ('got', 670.20097443398708),\n",
       " ('isn', 663.38770492284993),\n",
       " ('links', 658.77816987326935),\n",
       " ('mean', 657.35833905220397),\n",
       " ('remove', 655.69282111849839),\n",
       " ('long', 655.26386418543825),\n",
       " ('life', 651.76589625855718),\n",
       " ('free', 651.18768345423587),\n",
       " ('ip', 644.58817134907736),\n",
       " ('trying', 644.52026242496572),\n",
       " ('come', 642.70654735141204),\n",
       " ('understand', 642.70423972955291),\n",
       " ('delete', 637.58727150904213),\n",
       " ('using', 635.02129548593359),\n",
       " ('english', 634.90220253162352),\n",
       " ('reference', 633.29448382174201),\n",
       " ('world', 631.9432580246139),\n",
       " ('try', 621.44184677460044),\n",
       " ('editor', 620.15970507850807),\n",
       " ('day', 616.30033096459897),\n",
       " ('request', 614.44926360597151),\n",
       " ('doing', 613.19440958557027),\n",
       " ('issue', 612.3202872643526),\n",
       " ('references', 610.53096290455187),\n",
       " ('ask', 607.94105617371793),\n",
       " ('great', 603.85366347708805),\n",
       " ('hello', 600.26861523909838),\n",
       " ('says', 597.44685172132665),\n",
       " ('leave', 597.43350643089707),\n",
       " ('thought', 594.27404109276688),\n",
       " ('years', 592.38056611283605),\n",
       " ('making', 590.54458208168285),\n",
       " ('word', 590.50306592100253),\n",
       " ('reverted', 590.34300099728807),\n",
       " ('probably', 588.9104331549695),\n",
       " ('text', 583.36008837564123),\n",
       " ('different', 583.01444036754015),\n",
       " ('needs', 581.89132557624407),\n",
       " ('post', 581.32674937101979),\n",
       " ('policy', 576.11860212215959),\n",
       " ('maybe', 574.64509026393296),\n",
       " ('site', 573.73406779029574),\n",
       " ('hey', 571.8290077686836),\n",
       " ('called', 571.08735001974742),\n",
       " ('support', 569.34729680451846),\n",
       " ('fucking', 569.20413823715955),\n",
       " ('reliable', 568.31301972504934),\n",
       " ('message', 565.7106506403486),\n",
       " ('subject', 564.40145070809456),\n",
       " ('ok', 555.25102922578026),\n",
       " ('account', 554.94552862326157),\n",
       " ('state', 553.28755936990956),\n",
       " ('correct', 549.8324399409438),\n",
       " ('war', 549.09935954977709),\n",
       " ('real', 548.8639651660701),\n",
       " ('far', 543.95397055722822),\n",
       " ('consensus', 542.29988755658042),\n",
       " ('revert', 540.918307732519),\n",
       " ('title', 537.64934068525815),\n",
       " ('admin', 535.54916823438737),\n",
       " ('tell', 534.29684576006321),\n",
       " ('original', 534.08323742485709),\n",
       " ('opinion', 533.54324061594298),\n",
       " ('check', 533.51181702987128),\n",
       " ('man', 531.98339880284072),\n",
       " ('bit', 519.7626082791669),\n",
       " ('book', 518.80153045861459),\n",
       " ('adding', 518.28884742157538),\n",
       " ('non', 517.16381034112806),\n",
       " ('pov', 515.60370450942639),\n",
       " ('lot', 512.45700687599492),\n",
       " ('www', 512.36139186672744),\n",
       " ('created', 512.12137441691334),\n",
       " ('example', 511.49491050742216),\n",
       " ('oh', 511.06853573967521),\n",
       " ('mention', 506.03523446534069),\n",
       " ('matter', 505.85837013838841),\n",
       " ('true', 504.02987505594791),\n",
       " ('contribs', 503.65138159589196),\n",
       " ('old', 503.33250913393618),\n",
       " ('simply', 501.91859805964481),\n",
       " ('having', 500.26154201149632),\n",
       " ('tag', 499.79438382568532),\n",
       " ('quite', 495.16497338838815),\n",
       " ('given', 493.93412682653769),\n",
       " ('saying', 491.82577982068904),\n",
       " ('template', 491.50900128316289),\n",
       " ('notable', 491.03130229801275),\n",
       " ('clearly', 488.50863924182744),\n",
       " ('bad', 487.7524279482875),\n",
       " ('evidence', 483.5648849010737),\n",
       " ('users', 480.93581513109018),\n",
       " ('term', 480.48963003884325),\n",
       " ('review', 478.26410637524287),\n",
       " ('dont', 476.85818069673257),\n",
       " ('material', 476.28733147627753),\n",
       " ('considered', 475.18856437795444),\n",
       " ('left', 474.65362067750368),\n",
       " ('version', 472.01233494148119),\n",
       " ('states', 471.66685065856876),\n",
       " ('language', 471.44744783294186),\n",
       " ('year', 470.66523830308574),\n",
       " ('instead', 469.94049848699774),\n",
       " ('important', 469.42822516756064),\n",
       " ('number', 468.12152753071285),\n",
       " ('clear', 467.42018592393038),\n",
       " ('encyclopedia', 466.83530898770687),\n",
       " ('idea', 465.60151473339806),\n",
       " ('times', 465.02101502184939),\n",
       " ('write', 462.83581853129647),\n",
       " ('contributions', 459.72228735572054),\n",
       " ('view', 455.90186562360338),\n",
       " ('written', 454.76223210199657),\n",
       " ('changes', 452.48346023593513),\n",
       " ('makes', 451.67820421804134),\n",
       " ('website', 447.96371562415129),\n",
       " ('vandalize', 445.61648729775351),\n",
       " ('mentioned', 443.87205663270908),\n",
       " ('claim', 442.65359342496834),\n",
       " ('attack', 440.70848390353603),\n",
       " ('big', 439.45988559852805),\n",
       " ('second', 438.60753248171619),\n",
       " ('listed', 437.91945232926099),\n",
       " ('regarding', 435.54502621484772),\n",
       " ('care', 434.98381527717788),\n",
       " ('start', 434.65284948983503),\n",
       " ('questions', 433.57236693164259),\n",
       " ('changed', 433.00650446045034),\n",
       " ('main', 432.48671271693257),\n",
       " ('research', 431.9956787124267),\n",
       " ('warning', 430.93098154387025),\n",
       " ('seen', 430.64543128230196),\n",
       " ('suggest', 430.06174059767733),\n",
       " ('means', 429.88302871433677),\n",
       " ('end', 428.15084852812373),\n",
       " ('love', 426.37128635484851),\n",
       " ('course', 426.26103384130954),\n",
       " ('kind', 424.65061717797164),\n",
       " ('american', 424.60681228701998),\n",
       " ('won', 424.27365017235473),\n",
       " ('org', 424.0514446287911),\n",
       " ('getting', 423.96818698221375),\n",
       " ('copyright', 423.65944370923279),\n",
       " ('info', 423.46776253868899),\n",
       " ('mind', 423.38659105020793),\n",
       " ('words', 422.03056285850164),\n",
       " ('images', 416.93743702824895),\n",
       " ('possible', 415.65804723389709),\n",
       " ('current', 415.46062136535909),\n",
       " ('based', 413.25534710674901),\n",
       " ('address', 410.63755658864159),\n",
       " ('consider', 408.21286267048572),\n",
       " ('nice', 408.17141298804353),\n",
       " ('looks', 406.10811742533787),\n",
       " ('happy', 405.9030460908042),\n",
       " ('known', 404.85341417560551),\n",
       " ('style', 402.42845912181184),\n",
       " ('topic', 400.62508781343121),\n",
       " ('fair', 395.4413655777592),\n",
       " ('speedy', 395.28118844412143),\n",
       " ('facts', 393.75868522460587),\n",
       " ('school', 393.13494240318636),\n",
       " ('statement', 392.2109984148953),\n",
       " ('cheers', 388.13688723765932),\n",
       " ('sense', 387.1586117331733),\n",
       " ('issues', 386.99607616903234),\n",
       " ('sentence', 385.51149672585359),\n",
       " ('picture', 385.46264006989998),\n",
       " ('guy', 385.2716515788394),\n",
       " ('include', 384.97168184668516),\n",
       " ('stuff', 384.60593687214555),\n",
       " ('days', 383.32502463329848),\n",
       " ('looking', 382.51673298373947),\n",
       " ('explain', 382.42601642491229),\n",
       " ('related', 381.24582212895666),\n",
       " ('line', 380.27775682002573),\n",
       " ('away', 380.04953023138034),\n",
       " ('date', 379.98715937193725),\n",
       " ('anti', 378.32444297996278),\n",
       " ('group', 373.7975268980075),\n",
       " ('project', 373.73689222277079),\n",
       " ('general', 372.80937256840429),\n",
       " ('guess', 368.70013094347712),\n",
       " ('wasn', 367.49200052880252),\n",
       " ('removing', 367.17598611090762),\n",
       " ('sandbox', 366.84173344840673),\n",
       " ('news', 365.91051497291807),\n",
       " ('following', 364.19737278372486),\n",
       " ('talking', 363.32138654724446),\n",
       " ('report', 363.11808844591008),\n",
       " ('notice', 361.32318640524159),\n",
       " ('pretty', 361.17747278689592),\n",
       " ('rules', 360.35030844340071),\n",
       " ('create', 357.24252858828737),\n",
       " ('official', 356.88314089479218),\n",
       " ('interested', 356.49769266504927),\n",
       " ('appropriate', 356.12247539337841),\n",
       " ('discuss', 355.37926074997699),\n",
       " ('relevant', 354.79054390676521),\n",
       " ('started', 351.22968990380014),\n",
       " ('wish', 350.84720095310178),\n",
       " ('later', 349.89011942667321),\n",
       " ('including', 349.73403334542422),\n",
       " ('answer', 349.32063812058755),\n",
       " ('recent', 348.65592703276292),\n",
       " ('order', 346.62462339014616),\n",
       " ('regards', 346.61863569802307),\n",
       " ('en', 346.39891185455753),\n",
       " ('reverting', 344.39058181202364),\n",
       " ('country', 344.0217035777199),\n",
       " ('provide', 343.00670829294086),\n",
       " ('wrote', 342.01624907562984),\n",
       " ('able', 340.60556687899452),\n",
       " ('writing', 339.25199001440762),\n",
       " ('attacks', 338.87624271973141),\n",
       " ('wanted', 338.73429995806214),\n",
       " ('today', 336.53963473798615),\n",
       " ('self', 336.36741706068432),\n",
       " ('especially', 336.12191022151808),\n",
       " ('hard', 335.49885281996677),\n",
       " ('fine', 335.47684360640488),\n",
       " ('certainly', 334.53804481445673),\n",
       " ('learn', 333.91506344650543),\n",
       " ('media', 333.61056886668064),\n",
       " ('names', 333.26605991535888),\n",
       " ('according', 332.13494860576731),\n",
       " ('reply', 331.98912736330232),\n",
       " ('taken', 331.82387661162011),\n",
       " ('truth', 331.40956769642492),\n",
       " ('response', 331.07373650216692),\n",
       " ('obviously', 330.03539025428205),\n",
       " ('high', 329.67967715465164),\n",
       " ('common', 329.48700855179607),\n",
       " ('exactly', 329.14762403671102),\n",
       " ('included', 328.91919200938923),\n",
       " ('unless', 328.68078094480984),\n",
       " ('working', 326.15987900743681),\n",
       " ('neutral', 325.98373246792562),\n",
       " ('future', 324.42127890888634),\n",
       " ('currently', 323.08408906847893),\n",
       " ('claims', 322.81092834672057),\n",
       " ('haven', 322.53007057386139),\n",
       " ('single', 322.13714593511298),\n",
       " ('ago', 322.03285503426793),\n",
       " ('entry', 319.48803737456518),\n",
       " ('lead', 316.32897632135132),\n",
       " ('public', 315.46147197762366),\n",
       " ('completely', 315.3543676799012),\n",
       " ('quote', 314.04935574845354),\n",
       " ('community', 312.73405639280253),\n",
       " ('appears', 309.6122174114023),\n",
       " ('faith', 309.36218027000416),\n",
       " ('guidelines', 309.19376999019426),\n",
       " ('remember', 308.55245823406176),\n",
       " ('appreciate', 305.76114065895592),\n",
       " ('needed', 305.36103230042704),\n",
       " ('came', 302.66678388630049),\n",
       " ('notability', 302.34861203890938),\n",
       " ('soon', 301.15723102714992),\n",
       " ('deleting', 301.08294205936448),\n",
       " ('specific', 300.73604980198576),\n",
       " ('took', 300.47277835133565),\n",
       " ('involved', 299.49705772992723),\n",
       " ('reading', 299.13584552569301),\n",
       " ('political', 298.75339534055314),\n",
       " ('similar', 296.07429650284121),\n",
       " ('edited', 295.64760699567012),\n",
       " ('past', 295.62496760726572),\n",
       " ('search', 295.01852561978097),\n",
       " ('stay', 293.19296112783076),\n",
       " ('summary', 292.61093055545632),\n",
       " ('sign', 292.36445534933915),\n",
       " ('noticed', 289.38886589690509),\n",
       " ('posted', 288.79918987669186),\n",
       " ('published', 286.26048405393982),\n",
       " ('asked', 282.9771025109701),\n",
       " ('process', 282.7672144167733),\n",
       " ('argument', 280.51555940789416),\n",
       " ('tried', 279.65323751910529),\n",
       " ('taking', 278.76571308465174),\n",
       " ('useful', 277.60368109249481),\n",
       " ('major', 277.07526794202198),\n",
       " ('criteria', 275.42617260792355),\n",
       " ('sort', 274.60152454643878),\n",
       " ('problems', 272.20270030076188),\n",
       " ('form', 268.63317390092152),\n",
       " ('likely', 266.30277477329059),\n",
       " ('position', 265.2073739120201),\n",
       " ('reasons', 260.88003806029764),\n",
       " ('provided', 259.89926680237807),\n",
       " ('policies', 257.50695414887048),\n",
       " ('stated', 254.26344224372747),\n",
       " ('particular', 251.94102959303382),\n",
       " ('follow', 250.2335062106761),\n",
       " ('contributing', 243.83457368229307),\n",
       " ('aware', 222.23096000006029),\n",
       " ('placed', 220.28711653741729),\n",
       " ('generally', 200.31337867855748)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort according to descending frequencies\n",
    "freqs = sorted (freqs, key = lambda x: -x[1])\n",
    "\n",
    "freqs[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 4321.8949476516764),\n",
       " ('talk', 3820.5104084668023),\n",
       " ('page', 3668.4520826854882),\n",
       " ('wikipedia', 3424.1755082641116),\n",
       " ('just', 2714.8821694465723),\n",
       " ('like', 2597.0727662851423),\n",
       " ('don', 2376.5895142112308),\n",
       " ('think', 2118.7716297940392),\n",
       " ('thanks', 2093.9664615955985),\n",
       " ('know', 2057.4652060076687),\n",
       " ('edit', 1900.3938575417055),\n",
       " ('did', 1789.6721646821111),\n",
       " ('people', 1788.7361713914952),\n",
       " ('time', 1626.6123629592287),\n",
       " ('user', 1606.7188489166583),\n",
       " ('articles', 1519.6724048061656),\n",
       " ('good', 1510.8332682582102),\n",
       " ('ve', 1499.9589891412586),\n",
       " ('use', 1461.6857807546983),\n",
       " ('utc', 1430.6549936765032),\n",
       " ('make', 1368.6261787584556),\n",
       " ('does', 1340.9671379148226),\n",
       " ('thank', 1334.5291603240833),\n",
       " ('want', 1294.5473379435036),\n",
       " ('wp', 1277.1351585728969),\n",
       " ('way', 1241.6865835226322),\n",
       " ('stop', 1214.2135395009948),\n",
       " ('section', 1212.7645095475239),\n",
       " ('editing', 1206.3453001535918),\n",
       " ('new', 1203.8662510946499),\n",
       " ('information', 1201.1335735859916),\n",
       " ('say', 1193.887875278079),\n",
       " ('edits', 1191.0580513527386),\n",
       " ('sources', 1186.5466122654605),\n",
       " ('source', 1176.9332094111257),\n",
       " ('blocked', 1165.1923961504235),\n",
       " ('need', 1148.9858297594121),\n",
       " ('ll', 1145.6115295720845),\n",
       " ('really', 1131.9929091712406),\n",
       " ('help', 1122.7435246493103),\n",
       " ('pages', 1121.8625250862508),\n",
       " ('right', 1117.176265494991),\n",
       " ('discussion', 1076.9875447599977),\n",
       " ('look', 1063.0734238385576),\n",
       " ('work', 1051.2587489044577),\n",
       " ('read', 1004.2614337953589),\n",
       " ('going', 980.86084098768583),\n",
       " ('used', 975.81833323192325),\n",
       " ('deletion', 973.84022232892164),\n",
       " ('add', 954.27387014463295),\n",
       " ('said', 949.01725074279932),\n",
       " ('added', 946.99161052811542),\n",
       " ('list', 937.45897541276076),\n",
       " ('point', 935.7990806823135),\n",
       " ('fuck', 930.04332256042903),\n",
       " ('link', 914.15414859337193),\n",
       " ('removed', 913.40206561747345),\n",
       " ('image', 910.78907270558),\n",
       " ('vandalism', 902.09752264364897),\n",
       " ('block', 899.48440326719765),\n",
       " ('hi', 898.35657770867374),\n",
       " ('fact', 888.47272648821593),\n",
       " ('wiki', 881.40780348854958),\n",
       " ('redirect', 874.83038754740471),\n",
       " ('sure', 870.94666409190461),\n",
       " ('sorry', 869.53963777729246),\n",
       " ('deleted', 867.27863479806638),\n",
       " ('better', 858.57317623963399),\n",
       " ('comment', 855.2837925688209),\n",
       " ('history', 839.41412960517414),\n",
       " ('let', 833.72358726267669),\n",
       " ('doesn', 801.32252430079825),\n",
       " ('reason', 796.22213787553369),\n",
       " ('http', 794.98196943645337),\n",
       " ('actually', 788.4097962452629),\n",
       " ('case', 784.07459223514638),\n",
       " ('didn', 772.98413303085454),\n",
       " ('content', 766.18708246282108),\n",
       " ('comments', 744.56787818699945),\n",
       " ('wrong', 744.56516805042872),\n",
       " ('agree', 743.72812402881482),\n",
       " ('change', 740.82046166522514),\n",
       " ('editors', 736.94800467321988),\n",
       " ('personal', 732.71740506017875),\n",
       " ('yes', 728.61872964782367),\n",
       " ('little', 727.23100339952987),\n",
       " ('believe', 722.71517381777448),\n",
       " ('thing', 721.58101117910178),\n",
       " ('welcome', 718.5225621481718),\n",
       " ('place', 716.69188636367471),\n",
       " ('question', 716.53587233922008),\n",
       " ('continue', 709.60911382727841),\n",
       " ('problem', 708.03907270737125),\n",
       " ('person', 698.00063163832908),\n",
       " ('note', 696.52951162248326),\n",
       " ('com', 693.13347955862105),\n",
       " ('hope', 692.90712195006574),\n",
       " ('things', 687.73315072152332),\n",
       " ('best', 682.74292880923417),\n",
       " ('feel', 673.23101101873817),\n",
       " ('got', 667.23274170467619),\n",
       " ('isn', 657.6513066328024),\n",
       " ('mean', 654.03688456363841),\n",
       " ('links', 652.89734203915702),\n",
       " ('remove', 649.39193477777201),\n",
       " ('long', 649.25558397599366),\n",
       " ('life', 648.67399072864248),\n",
       " ('free', 646.11932953171811),\n",
       " ('ip', 643.0944952530989),\n",
       " ('trying', 639.96651562806073),\n",
       " ('come', 639.23102457949358),\n",
       " ('understand', 638.99363945305856),\n",
       " ('using', 631.7245016034334),\n",
       " ('delete', 631.5048977925419),\n",
       " ('english', 630.40108106618334),\n",
       " ('world', 628.54623389106666),\n",
       " ('reference', 626.93445909576224),\n",
       " ('try', 617.47964671094735),\n",
       " ('editor', 615.67559008510261),\n",
       " ('day', 613.59463700212473),\n",
       " ('request', 611.05117561124132),\n",
       " ('doing', 610.00041913779364),\n",
       " ('issue', 607.52162167366509),\n",
       " ('ask', 604.12105985564506),\n",
       " ('references', 602.43459673470852),\n",
       " ('great', 599.77979842094044),\n",
       " ('hello', 596.48770286593356),\n",
       " ('leave', 592.1244416096979),\n",
       " ('says', 591.88049269251064),\n",
       " ('thought', 590.47109026996077),\n",
       " ('years', 588.51422877114283),\n",
       " ('word', 586.92489133436334),\n",
       " ('reverted', 586.87879806551507),\n",
       " ('making', 586.22710672379299),\n",
       " ('probably', 583.91491798344794),\n",
       " ('post', 578.44384488972457),\n",
       " ('different', 577.96756498707532),\n",
       " ('text', 577.40001961988219),\n",
       " ('policy', 572.96661519680981),\n",
       " ('needs', 572.80560965994141),\n",
       " ('site', 571.32716193726003),\n",
       " ('maybe', 571.15528272379777),\n",
       " ('hey', 569.35863284168704),\n",
       " ('fucking', 568.56559219559233),\n",
       " ('called', 566.66714992856021),\n",
       " ('support', 565.11287984904232),\n",
       " ('message', 563.35420070245357),\n",
       " ('reliable', 562.75438930776102),\n",
       " ('subject', 553.85861082754025),\n",
       " ('account', 553.30697656859866),\n",
       " ('ok', 553.20054119609085),\n",
       " ('state', 548.90785424526928),\n",
       " ('real', 545.91874299773053),\n",
       " ('war', 545.6057548462079),\n",
       " ('correct', 545.40800996927499),\n",
       " ('far', 539.05642374309832),\n",
       " ('consensus', 537.80042537378608),\n",
       " ('revert', 537.44263890149386),\n",
       " ('admin', 533.81511725268911),\n",
       " ('tell', 531.59643982583839),\n",
       " ('title', 531.26801748057767),\n",
       " ('man', 529.90349194176963),\n",
       " ('check', 529.84120908828083),\n",
       " ('original', 529.52742068402245),\n",
       " ('opinion', 528.67410514824701),\n",
       " ('bit', 516.19997217160687),\n",
       " ('book', 515.2763878104098),\n",
       " ('non', 513.32124975725003),\n",
       " ('adding', 512.59538595609763),\n",
       " ('www', 510.11204714446438),\n",
       " ('pov', 509.8401905694912),\n",
       " ('oh', 509.5336907773555),\n",
       " ('lot', 507.86328422442517),\n",
       " ('example', 507.15742913457842),\n",
       " ('created', 504.07758052482706),\n",
       " ('matter', 502.30753823610257),\n",
       " ('true', 501.42669557835171),\n",
       " ('contribs', 501.37152998027841),\n",
       " ('old', 501.02507160298796),\n",
       " ('mention', 499.1477723617711),\n",
       " ('simply', 497.9607168169573),\n",
       " ('having', 496.45433438140191),\n",
       " ('tag', 491.90294025479614),\n",
       " ('quite', 490.77112511923985),\n",
       " ('given', 489.3119849373611),\n",
       " ('saying', 488.94910566924852),\n",
       " ('template', 487.97316485201452),\n",
       " ('bad', 485.03516921385705),\n",
       " ('clearly', 484.64052517752134),\n",
       " ('notable', 482.86872454044214),\n",
       " ('evidence', 481.05273572711587),\n",
       " ('users', 478.71232569183547),\n",
       " ('term', 477.265207782272),\n",
       " ('dont', 475.36502496387067),\n",
       " ('considered', 472.93654749306592),\n",
       " ('review', 472.32089152393098),\n",
       " ('left', 471.29248820708546),\n",
       " ('material', 470.35153375001642),\n",
       " ('language', 468.42807994897981),\n",
       " ('year', 468.25565767894784),\n",
       " ('version', 467.62199103684861),\n",
       " ('states', 466.87017863094292),\n",
       " ('instead', 466.05270500381192),\n",
       " ('important', 464.67707816141177),\n",
       " ('number', 464.60161786173052),\n",
       " ('clear', 463.8309673408545),\n",
       " ('encyclopedia', 462.93410581135339),\n",
       " ('idea', 462.11609503156171),\n",
       " ('times', 461.70032898354225),\n",
       " ('write', 458.37176997990849),\n",
       " ('contributions', 456.10519516252464),\n",
       " ('view', 451.82883736683874),\n",
       " ('makes', 448.44877922424155),\n",
       " ('written', 448.22884459509135),\n",
       " ('changes', 447.82460698397381),\n",
       " ('vandalize', 445.31599364644859),\n",
       " ('website', 445.24866069701164),\n",
       " ('claim', 439.36288965717137),\n",
       " ('attack', 439.30444335154067),\n",
       " ('mentioned', 437.79741848619733),\n",
       " ('big', 437.13931635195758),\n",
       " ('second', 435.79403441919214),\n",
       " ('listed', 434.807324802631),\n",
       " ('care', 432.5806304200222),\n",
       " ('regarding', 431.86816194840492),\n",
       " ('questions', 430.09591928260238),\n",
       " ('start', 430.02621787401915),\n",
       " ('warning', 429.54795814181847),\n",
       " ('changed', 429.51714716994252),\n",
       " ('research', 428.90494894257762),\n",
       " ('seen', 428.15888981401889),\n",
       " ('means', 427.20773097553086),\n",
       " ('end', 425.54327614328491),\n",
       " ('love', 424.99150064703872),\n",
       " ('suggest', 424.7410096202496),\n",
       " ('main', 424.06348117267947),\n",
       " ('course', 423.29114916674183),\n",
       " ('won', 422.31636296954593),\n",
       " ('kind', 422.151912638353),\n",
       " ('copyright', 421.92643807411196),\n",
       " ('org', 421.925438648453),\n",
       " ('american', 421.87763378012676),\n",
       " ('getting', 421.28343118484594),\n",
       " ('mind', 421.07543928389487),\n",
       " ('info', 419.81169526559063),\n",
       " ('words', 419.30274928048243),\n",
       " ('images', 414.32952247608921),\n",
       " ('possible', 412.13661229676251),\n",
       " ('current', 410.5966983965908),\n",
       " ('based', 409.33719327211429),\n",
       " ('address', 408.83058970642799),\n",
       " ('nice', 405.93224228608989),\n",
       " ('consider', 405.1100855089731),\n",
       " ('happy', 403.74656648502184),\n",
       " ('looks', 403.1845555666003),\n",
       " ('known', 402.06454704717515),\n",
       " ('style', 399.73960061344548),\n",
       " ('topic', 395.76442144146836),\n",
       " ('fair', 393.20015342875143),\n",
       " ('school', 391.08139444071207),\n",
       " ('facts', 390.70162811611317),\n",
       " ('statement', 389.18372539607992),\n",
       " ('speedy', 387.45277543342121),\n",
       " ('cheers', 385.68773025813164),\n",
       " ('sense', 384.48819932284937),\n",
       " ('guy', 383.86190009257308),\n",
       " ('picture', 383.23236005199783),\n",
       " ('issues', 382.50039510189185),\n",
       " ('stuff', 381.90571756037383),\n",
       " ('sentence', 381.77891995050379),\n",
       " ('include', 380.75308637693598),\n",
       " ('days', 380.61811379851002),\n",
       " ('looking', 379.6100639745315),\n",
       " ('explain', 378.94251947478898),\n",
       " ('related', 378.30048761460097),\n",
       " ('away', 377.99251264482501),\n",
       " ('line', 377.63317449248098),\n",
       " ('date', 377.38073284510955),\n",
       " ('anti', 375.85644672939276),\n",
       " ('project', 370.8292248171802),\n",
       " ('group', 370.43483171061746),\n",
       " ('general', 368.00363086799479),\n",
       " ('guess', 367.11666118934772),\n",
       " ('sandbox', 365.96951069846045),\n",
       " ('wasn', 365.58664146252977),\n",
       " ('removing', 364.40860518323302),\n",
       " ('news', 362.74048748555907),\n",
       " ('report', 361.63368284156923),\n",
       " ('talking', 361.55792618674207),\n",
       " ('following', 360.98364720904016),\n",
       " ('rules', 358.48311213357903),\n",
       " ('pretty', 358.24855246269112),\n",
       " ('notice', 357.82023558045296),\n",
       " ('official', 355.01631980929534),\n",
       " ('interested', 353.62154644938471),\n",
       " ('create', 352.80759264344425),\n",
       " ('appropriate', 351.48822785471691),\n",
       " ('discuss', 351.1021491072662),\n",
       " ('relevant', 349.64304123499016),\n",
       " ('wish', 348.79191111243415),\n",
       " ('started', 348.03975395577567),\n",
       " ('answer', 347.82049266160584),\n",
       " ('later', 346.96017213781937),\n",
       " ('including', 346.46153800449571),\n",
       " ('recent', 345.15370541257039),\n",
       " ('en', 344.73015917786574),\n",
       " ('regards', 344.06927801473063),\n",
       " ('order', 343.29971689307996),\n",
       " ('reverting', 342.44918014189352),\n",
       " ('country', 342.17660814714088),\n",
       " ('provide', 340.33419991617751),\n",
       " ('wrote', 338.2311700369836),\n",
       " ('able', 338.20202588334996),\n",
       " ('attacks', 337.45722582407831),\n",
       " ('wanted', 336.48455792961494),\n",
       " ('writing', 335.68335629753489),\n",
       " ('self', 334.59721376996356),\n",
       " ('today', 334.02270154065877),\n",
       " ('especially', 333.62934823131803),\n",
       " ('fine', 333.36414649961421),\n",
       " ('hard', 333.30242097951873),\n",
       " ('learn', 333.01843660308595),\n",
       " ('certainly', 331.77750358163189),\n",
       " ('media', 331.73931331846205),\n",
       " ('names', 331.06407688242751),\n",
       " ('reply', 330.61547205624777),\n",
       " ('truth', 329.97995599064132),\n",
       " ('taken', 329.32835592546337),\n",
       " ('according', 329.29426665622299),\n",
       " ('response', 329.27807743781034),\n",
       " ('obviously', 327.96678660874073),\n",
       " ('high', 327.77654475358929),\n",
       " ('exactly', 327.38447936244842),\n",
       " ('common', 327.21485288335515),\n",
       " ('unless', 325.90869773216127),\n",
       " ('included', 324.32238015205428),\n",
       " ('working', 323.14397023291679),\n",
       " ('future', 322.24126092286929),\n",
       " ('neutral', 321.99816385380723),\n",
       " ('haven', 320.66054314788164),\n",
       " ('ago', 319.92399127305583),\n",
       " ('currently', 319.60213667386671),\n",
       " ('claims', 319.59508717927292),\n",
       " ('single', 319.23156171177538),\n",
       " ('entry', 318.15856790883316),\n",
       " ('public', 313.59901123067584),\n",
       " ('completely', 313.01954573449734),\n",
       " ('lead', 312.76215663915775),\n",
       " ('quote', 311.94927154766151),\n",
       " ('community', 311.09581201128088),\n",
       " ('faith', 307.75168007285185),\n",
       " ('remember', 307.15401294648467),\n",
       " ('appears', 306.30016844160986),\n",
       " ('guidelines', 304.28113182729777),\n",
       " ('appreciate', 303.60379384429905),\n",
       " ('needed', 302.76488139428),\n",
       " ('came', 300.51692181366752),\n",
       " ('soon', 299.56418478822673),\n",
       " ('took', 299.12128022118213),\n",
       " ('deleting', 298.6505068982965),\n",
       " ('specific', 297.26615437957986),\n",
       " ('involved', 297.09249042855373),\n",
       " ('notability', 297.07270541942125),\n",
       " ('political', 296.38303048659048),\n",
       " ('reading', 295.57363887000724),\n",
       " ('past', 293.49273121205863),\n",
       " ('similar', 293.29399087570312),\n",
       " ('search', 293.11658073178836),\n",
       " ('edited', 292.01145437728923),\n",
       " ('sign', 291.2374760062018),\n",
       " ('stay', 291.17683945056581),\n",
       " ('summary', 290.20441546213317),\n",
       " ('posted', 286.91516806132535),\n",
       " ('noticed', 286.57782793726392),\n",
       " ('published', 283.92134137596702),\n",
       " ('asked', 281.73182797091164),\n",
       " ('process', 279.17704176037307),\n",
       " ('argument', 278.52188485736565),\n",
       " ('tried', 277.59286323315575),\n",
       " ('taking', 276.92340734728475),\n",
       " ('useful', 274.77881371124471),\n",
       " ('major', 274.49876286100778),\n",
       " ('sort', 272.95372922400958),\n",
       " ('problems', 269.75177181135501),\n",
       " ('criteria', 269.04544526403794),\n",
       " ('form', 266.93027020333403),\n",
       " ('likely', 264.74316710588687),\n",
       " ('position', 262.31226288289821),\n",
       " ('reasons', 258.43373633701981),\n",
       " ('provided', 257.7982390066079),\n",
       " ('policies', 255.28131301606504),\n",
       " ('stated', 252.39039627034197),\n",
       " ('particular', 249.65399680251767),\n",
       " ('follow', 248.63020125856349),\n",
       " ('contributing', 243.08333840640427),\n",
       " ('aware', 220.47616917532457),\n",
       " ('placed', 216.08647988000075),\n",
       " ('generally', 198.34122635333173)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort according to descending frequencies\n",
    "freqs = sorted (freqs, key = lambda x: -x[1])\n",
    "\n",
    "freqs[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning: Removing URLs (All test codes below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterCleanuper:\n",
    "\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"comment_text\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"comment_text\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\", \"\\n\"]):\n",
    "            tweets.loc[:, \"comment_text\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cleaner():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.processed_data = 0\n",
    "    \n",
    "    def cleanup(self, data, cleanuper):\n",
    "        t = data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            t = cleanup_method(t)\n",
    "        self.processed_data = t\n",
    "        \n",
    "    def getData(self):\n",
    "        return self.processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense  kiss off geek what I said is true  I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>Please do not vandalize pages as you did with...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>Points of interest I removed the points of in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense  kiss off geek what I said is true  I...      1   \n",
       "1  27450690   Please do not vandalize pages as you did with...      0   \n",
       "2  54037174   Points of interest I removed the points of in...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup = TwitterCleanuper()\n",
    "cleaner = Cleaner()\n",
    "cleaner.cleanup(trainData, cleanup)\n",
    "trainData = cleaner.getData()\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_TokenStem():\n",
    "    def __init__(self, data):\n",
    "        self.processed_data = data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"comment_text\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"comment_text\"]))\n",
    "            return row\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"comment_text\"] = tokenizer(row[\"comment_text\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"comment_text\"]\n",
    "            return row\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)\n",
    "        \n",
    "    def getData(self):\n",
    "        return self.processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = TwitterData_TokenStem(data)\n",
    "stemmer.tokenize()\n",
    "stemmer.stem()\n",
    "data = stemmer.getData()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "for idx in data.index:\n",
    "    words.update(data.loc[idx, \"comment_text\"])\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-65b37cac269a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-65b37cac269a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    install nltk(\"word_list\")\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "install nltk(\"word_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matthew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
