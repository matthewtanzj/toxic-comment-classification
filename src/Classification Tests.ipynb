{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:30.098617Z",
     "start_time": "2017-12-25T12:40:29.531619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from textstat.textstat import textstat\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# from NbSvmClassifier import NbSvmClassifier\n",
    "\n",
    "# BoW feature extraction\n",
    "import re, string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.643617Z",
     "start_time": "2017-12-25T12:40:30.099620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = '../data/train.csv'\n",
    "test_file = '../data/test.csv'\n",
    "sample_submission_file = '../data/sample_submission.csv'\n",
    "\n",
    "train_all = pd.read_csv(train_file)\n",
    "test_for_submission = pd.read_csv(test_file)\n",
    "sample_submission = pd.read_csv(sample_submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Account for more cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.674621Z",
     "start_time": "2017-12-25T12:40:31.644620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "test_for_submission['comment_text'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.682621Z",
     "start_time": "2017-12-25T12:40:31.675622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=0)\n",
    "cv_splits_train = []\n",
    "cv_splits_test = []\n",
    "for train_index, test_index in kf.split(train_all):\n",
    "    cv_splits_train.append(train_index)\n",
    "    cv_splits_test.append(test_index)\n",
    "cv_folds = len(cv_splits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.744617Z",
     "start_time": "2017-12-25T12:40:31.683622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_train = []\n",
    "cv_test = []\n",
    "for i in range(cv_folds):\n",
    "    cv_train.append(train_all.loc[cv_splits_train[i], :])\n",
    "    cv_test.append(train_all.loc[cv_splits_test[i], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.748619Z",
     "start_time": "2017-12-25T12:40:31.745621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = cv_train\n",
    "test = cv_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count and check that the data is split such that the percentages of labels in train/test are roughly equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.756619Z",
     "start_time": "2017-12-25T12:40:31.749621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.850618Z",
     "start_time": "2017-12-25T12:40:31.757619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV train 0\n",
      "        toxic: 7366 / 76680 (9.606%)\n",
      " severe_toxic: 792 / 76680 (1.033%)\n",
      "      obscene: 4108 / 76680 (5.357%)\n",
      "       threat: 234 / 76680 (0.305%)\n",
      "       insult: 3826 / 76680 (4.99%)\n",
      "identity_hate: 654 / 76680 (0.853%)\n",
      "CV test 0\n",
      "        toxic: 1871 / 19171 (9.76%)\n",
      " severe_toxic: 173 / 19171 (0.902%)\n",
      "      obscene: 1001 / 19171 (5.221%)\n",
      "       threat: 71 / 19171 (0.37%)\n",
      "       insult: 939 / 19171 (4.898%)\n",
      "identity_hate: 160 / 19171 (0.835%)\n",
      "CV train 1\n",
      "        toxic: 7413 / 76681 (9.667%)\n",
      " severe_toxic: 772 / 76681 (1.007%)\n",
      "      obscene: 4136 / 76681 (5.394%)\n",
      "       threat: 244 / 76681 (0.318%)\n",
      "       insult: 3841 / 76681 (5.009%)\n",
      "identity_hate: 657 / 76681 (0.857%)\n",
      "CV test 1\n",
      "        toxic: 1824 / 19170 (9.515%)\n",
      " severe_toxic: 193 / 19170 (1.007%)\n",
      "      obscene: 973 / 19170 (5.076%)\n",
      "       threat: 61 / 19170 (0.318%)\n",
      "       insult: 924 / 19170 (4.82%)\n",
      "identity_hate: 157 / 19170 (0.819%)\n",
      "CV train 2\n",
      "        toxic: 7397 / 76681 (9.646%)\n",
      " severe_toxic: 764 / 76681 (0.996%)\n",
      "      obscene: 4072 / 76681 (5.31%)\n",
      "       threat: 248 / 76681 (0.323%)\n",
      "       insult: 3795 / 76681 (4.949%)\n",
      "identity_hate: 651 / 76681 (0.849%)\n",
      "CV test 2\n",
      "        toxic: 1840 / 19170 (9.598%)\n",
      " severe_toxic: 201 / 19170 (1.049%)\n",
      "      obscene: 1037 / 19170 (5.409%)\n",
      "       threat: 57 / 19170 (0.297%)\n",
      "       insult: 970 / 19170 (5.06%)\n",
      "identity_hate: 163 / 19170 (0.85%)\n",
      "CV train 3\n",
      "        toxic: 7392 / 76681 (9.64%)\n",
      " severe_toxic: 769 / 76681 (1.003%)\n",
      "      obscene: 4068 / 76681 (5.305%)\n",
      "       threat: 254 / 76681 (0.331%)\n",
      "       insult: 3818 / 76681 (4.979%)\n",
      "identity_hate: 652 / 76681 (0.85%)\n",
      "CV test 3\n",
      "        toxic: 1845 / 19170 (9.624%)\n",
      " severe_toxic: 196 / 19170 (1.022%)\n",
      "      obscene: 1041 / 19170 (5.43%)\n",
      "       threat: 51 / 19170 (0.266%)\n",
      "       insult: 947 / 19170 (4.94%)\n",
      "identity_hate: 162 / 19170 (0.845%)\n",
      "CV train 4\n",
      "        toxic: 7380 / 76681 (9.624%)\n",
      " severe_toxic: 763 / 76681 (0.995%)\n",
      "      obscene: 4052 / 76681 (5.284%)\n",
      "       threat: 240 / 76681 (0.313%)\n",
      "       insult: 3780 / 76681 (4.93%)\n",
      "identity_hate: 642 / 76681 (0.837%)\n",
      "CV test 4\n",
      "        toxic: 1857 / 19170 (9.687%)\n",
      " severe_toxic: 202 / 19170 (1.054%)\n",
      "      obscene: 1057 / 19170 (5.514%)\n",
      "       threat: 65 / 19170 (0.339%)\n",
      "       insult: 985 / 19170 (5.138%)\n",
      "identity_hate: 172 / 19170 (0.897%)\n"
     ]
    }
   ],
   "source": [
    "def print_count_of_each_label(df):\n",
    "    for label in labels:\n",
    "        print('{}: {} / {} ({}%)'.format(label.rjust(len(labels[-1])),\n",
    "                                         df.loc[df[label] == 1].shape[0],\n",
    "                                         len(df),\n",
    "                                         np.round(df.loc[df[label] == 1].shape[0]/len(df)*100, 3)))\n",
    "\n",
    "for i in range(cv_folds):\n",
    "    print('CV train {}'.format(i))\n",
    "    print_count_of_each_label(cv_train[i])\n",
    "    print('CV test {}'.format(i))\n",
    "    print_count_of_each_label(cv_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train/test into X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can use sklearn classifiers easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.881617Z",
     "start_time": "2017-12-25T12:40:31.851619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [None] * cv_folds\n",
    "y_train = [None] * cv_folds\n",
    "X_test = [None] * cv_folds\n",
    "y_test = [None] * cv_folds\n",
    "for i in range(cv_folds):\n",
    "    X_train[i], y_train[i] = train[i][[\"comment_text\"]], train[i][labels]\n",
    "    X_test[i], y_test[i] = test[i][[\"comment_text\"]], test[i][labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.886620Z",
     "start_time": "2017-12-25T12:40:31.882620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76680, 1) (76680, 6)\n",
      "(19171, 1) (19171, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape, y_train[0].shape)\n",
    "print(X_test[0].shape, y_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.894619Z",
     "start_time": "2017-12-25T12:40:31.887619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features_df = pd.DataFrame()\n",
    "    features_df['comment_text_len'] = df['comment_text'].apply(len)\n",
    "    features_df['comment_text_lex_count'] = df['comment_text'].apply(textstat.lexicon_count)\n",
    "    features_df['comment_text_syl_count'] = df['comment_text'].apply(textstat.syllable_count)\n",
    "    features_df['comment_text_sent_count'] = df['comment_text'].apply(textstat.sentence_count)\n",
    "    features_df['comment_text_flesch_reading_ease'] = df['comment_text'].apply(textstat.flesch_reading_ease)\n",
    "    features_df['comment_text_flesch_kincaid_grade'] = df['comment_text'].apply(textstat.flesch_kincaid_grade)\n",
    "    \n",
    "    features_df['comment_text_syl_over_lex'] = features_df['comment_text_syl_count'] / features_df['comment_text_lex_count']\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:31.964621Z",
     "start_time": "2017-12-25T12:40:31.895622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_textstat_features_file = '../data/train_textstat_features.csv'\n",
    "if os.path.isfile(train_textstat_features_file):\n",
    "    X_train_all_features_textstat = pd.read_csv(train_textstat_features_file)\n",
    "else:\n",
    "    X_train_all_features_textstat = extract_features(train_all)\n",
    "    X_train_all_features_textstat.to_csv(train_textstat_features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T03:21:02.663558Z",
     "start_time": "2017-12-25T03:21:02.123907Z"
    }
   },
   "source": [
    "## Split textstat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:32.034619Z",
     "start_time": "2017-12-25T12:40:31.965620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_features_textstat = []\n",
    "X_test_features_textstat = []\n",
    "for i in range(cv_folds):\n",
    "    X_train_features_textstat.append(X_train_all_features_textstat.loc[cv_splits_train[i], :])\n",
    "    X_test_features_textstat.append(X_train_all_features_textstat.loc[cv_splits_test[i], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:32.038622Z",
     "start_time": "2017-12-25T12:40:32.035621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile('([{}“”¨«»®´·º½¾¿¡§£₤‘’])'.format(string.punctuation))\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:52.018354Z",
     "start_time": "2017-12-25T12:40:32.039620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = train_all.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "train_term_doc = vec.fit_transform(train_all['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:52.837355Z",
     "start_time": "2017-12-25T12:40:52.019357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_features_bow = []\n",
    "X_test_features_bow = []\n",
    "for i in range(cv_folds):\n",
    "    X_train_features_bow.append(train_term_doc[cv_splits_train[i], :])\n",
    "    X_test_features_bow.append(train_term_doc[cv_splits_test[i], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate mean column-wise log loss of y_pred vs y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:52.841361Z",
     "start_time": "2017-12-25T12:40:52.838357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_score(y_actual, y_pred):\n",
    "    return np.mean([log_loss(np.array(y_actual[label]),\n",
    "                             np.array([1.-np.array(y_pred[label]), np.array(y_pred[label])]).T) for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classification scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:52.870357Z",
     "start_time": "2017-12-25T12:40:52.842362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9920072216264108e-16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score(y_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:52.967354Z",
     "start_time": "2017-12-25T12:40:52.871356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2656350955831603, 1.2407774653431667, 1.2816162202528159, 1.2738088112259711, 1.3026361676327827]\n",
      "1.27289475201\n"
     ]
    }
   ],
   "source": [
    "scores_zeror = []\n",
    "for i in range(cv_folds):\n",
    "    data = np.array([np.zeros(len(labels))] * len(X_test[i]))\n",
    "    y_pred_zeror = pd.DataFrame(data, columns=labels)\n",
    "    scores_zeror.append(calculate_score(y_test[i], y_pred_zeror))\n",
    "print(scores_zeror)\n",
    "print(np.mean(scores_zeror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T12:28:47.459632Z",
     "start_time": "2017-12-24T12:28:47.455633Z"
    }
   },
   "source": [
    "## All 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:53.060357Z",
     "start_time": "2017-12-25T12:40:52.968357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529, 0.69314718055994529]\n",
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "scores_half = []\n",
    "for i in range(cv_folds):\n",
    "    data = np.array([np.ones(len(labels))*0.5] * len(X_test[i]))\n",
    "    y_pred_half = pd.DataFrame(data, columns=labels)\n",
    "    scores_half.append(calculate_score(y_test[i], y_pred_half))\n",
    "print(scores_half)\n",
    "print(np.mean(scores_half))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textstat features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T12:40:53.081357Z",
     "start_time": "2017-12-25T12:40:53.061358Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline-eda-0-052-lb#261316\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_x', '_y', '_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_x', '_y', '_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        # Store labels, X and y\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._classes = unique_labels(y)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "        self._r = np.log(pr(x,1,y) / pr(x,0,y))\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs)\n",
    "        \n",
    "        try:\n",
    "            x_nb = x * self._r\n",
    "        except:\n",
    "            x_nb = x.multiply(self._r)\n",
    "    \n",
    "        self._clf.fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T13:08:52.280820Z",
     "start_time": "2017-12-25T13:08:52.274319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers_textstat = [\n",
    "    \n",
    "    ('NB-SVM', NbSvmClassifier()),\n",
    "    \n",
    "    (\"Decision Tree\", DecisionTreeClassifier(max_depth=5)),\n",
    "    (\"Random Forest\", RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)),\n",
    "    (\"Extra Trees\", ExtraTreesClassifier(max_depth=5)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier()),\n",
    "    \n",
    "    # Does not perform too well, may need hyper parameter tuning\n",
    "    #     (\"Nearest Neighbors\", KNeighborsClassifier(131)),\n",
    "    #     (\"Naive Bayes\", GaussianNB()),\n",
    "    #     (\"Neural Net\", MLPClassifier(alpha=1)),\n",
    "    #     (\"AdaBoost\", AdaBoostClassifier()),\n",
    "    #     (\"QDA\", QuadraticDiscriminantAnalysis()),\n",
    "    \n",
    "    # Cannot even run\n",
    "    #     (\"Gaussian Process\", GaussianProcessClassifier(1.0 * RBF(1.0)))  # Memory error??? Even with 32GB ram???\n",
    "    #     (\"Linear SVM\", SVC(kernel=\"linear\", C=0.025)),                   # Slow like shit\n",
    "    #     (\"RBF SVM\", SVC(gamma=2, C=1))                                   # Slow like shit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T13:11:00.195376Z",
     "start_time": "2017-12-25T13:08:53.242135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with NB-SVM\n",
      "Column-wise log loss for NB-SVM: [0.18095665548136211, 0.17882501320839905, 0.18230149530739689, 0.18217079958540527, 0.18592839572795675] - 0.182036471862104\n",
      "Training with Decision Tree\n",
      "Column-wise log loss for Decision Tree: [0.18957052605820379, 0.17613638822970826, 0.1793007937950295, 0.18664318223035425, 0.22541131934805081] - 0.1914124419322693\n",
      "Training with Random Forest\n",
      "Column-wise log loss for Random Forest: [0.17240761235645463, 0.17024284803354539, 0.17496624440305722, 0.1744611051823873, 0.1716097767158847] - 0.17273751733826587\n",
      "Training with Extra Trees\n",
      "Column-wise log loss for Extra Trees: [0.17893788975208857, 0.17846357096391977, 0.18201174008308574, 0.17996148024629258, 0.18446533344684615] - 0.18076800289844655\n",
      "Training with Gradient Boosting\n",
      "Column-wise log loss for Gradient Boosting: [0.17491601261758297, 0.17192840005695872, 0.1770418719005408, 0.17536055567933465, 0.19379075699436746] - 0.1786075194497569\n"
     ]
    }
   ],
   "source": [
    "clf_textstat = {}\n",
    "y_pred_textstat = {}\n",
    "scores_textstat = {}\n",
    "for classifier_name, classifier in classifiers_textstat:\n",
    "    print('Training with {}'.format(classifier_name))\n",
    "    clf_textstat[classifier_name] = [{}]*cv_folds\n",
    "    y_pred_textstat[classifier_name] = [{}]*cv_folds\n",
    "    scores_textstat[classifier_name] = [{}]*cv_folds\n",
    "    for fold in range(cv_folds):\n",
    "        for label in labels:\n",
    "            clf_textstat[classifier_name][fold][label] = classifier\n",
    "            clf_textstat[classifier_name][fold][label].fit(X_train_features_textstat[fold], y_train[fold][label])\n",
    "\n",
    "        y_pred_textstat[classifier_name][fold] = pd.DataFrame()\n",
    "        for label in labels:\n",
    "            y_pred_textstat[classifier_name][fold][label] = clf_textstat[classifier_name][fold][label].predict_proba(X_test_features_textstat[fold]).T[1]\n",
    "\n",
    "        scores_textstat[classifier_name][fold] = calculate_score(y_test[fold], y_pred_textstat[classifier_name][fold])\n",
    "    print('Column-wise log loss for {}: {} - {}'.format(classifier_name, scores_textstat[classifier_name], np.mean(scores_textstat[classifier_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bag of words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T13:11:00.203378Z",
     "start_time": "2017-12-25T13:11:00.196377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers_bow = [\n",
    "    \n",
    "    ('NB-SVM 2', NbSvmClassifier(C=4, dual=True)),\n",
    "    ('NB-SVM', NbSvmClassifier()),\n",
    "    \n",
    "    (\"Decision Tree\", DecisionTreeClassifier(max_depth=5)),\n",
    "    (\"Random Forest\", RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)),\n",
    "    (\"Extra Trees\", ExtraTreesClassifier(max_depth=5)),\n",
    "    \n",
    "    #     (\"Gradient Boosting\", GradientBoostingClassifier()),           # Sloooow\n",
    "    \n",
    "    # Does not perform too well, may need hyper parameter tuning\n",
    "    #     (\"Nearest Neighbors\", KNeighborsClassifier(131)),\n",
    "    #     (\"Naive Bayes\", GaussianNB()),\n",
    "    #     (\"Neural Net\", MLPClassifier(alpha=1)),\n",
    "    #     (\"AdaBoost\", AdaBoostClassifier()),\n",
    "    #     (\"QDA\", QuadraticDiscriminantAnalysis()),\n",
    "    \n",
    "    # Cannot even run\n",
    "    #     (\"Gaussian Process\", GaussianProcessClassifier(1.0 * RBF(1.0)))  # Memory error??? Even with 32GB ram???\n",
    "    #     (\"Linear SVM\", SVC(kernel=\"linear\", C=0.025)),                   # Slow like shit\n",
    "    #     (\"RBF SVM\", SVC(gamma=2, C=1))                                   # Slow like shit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-25T13:19:21.253218Z",
     "start_time": "2017-12-25T13:11:00.204377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with NB-SVM 2\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Column-wise log loss for NB-SVM 2: [0.19844112468989492, 0.19392082828970536, 0.20404326571297679, 0.20250041765877583, 0.20624392623515853] - 0.2010299125173023\n",
      "Training with NB-SVM\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Column-wise log loss for NB-SVM: [0.16948686654519271, 0.16559772931639868, 0.17308711286704992, 0.17281802990400899, 0.17602815742741826] - 0.1714035792120137\n",
      "Training with Decision Tree\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Column-wise log loss for Decision Tree: [0.2035290665424109, 0.18481231106222365, 0.19680163652584448, 0.19196176863100647, 0.19546617070047986] - 0.19451419069239306\n",
      "Training with Random Forest\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Column-wise log loss for Random Forest: [0.18285599858864762, 0.1796933537266997, 0.18518115357689954, 0.18389392534292792, 0.18812967836177996] - 0.18395082191939097\n",
      "Training with Extra Trees\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Column-wise log loss for Extra Trees: [0.18045900002784809, 0.17882063418318894, 0.18243808525190167, 0.18279753960478862, 0.18705088105528553] - 0.18231322802460256\n"
     ]
    }
   ],
   "source": [
    "clf_bow = {}\n",
    "y_pred_bow = {}\n",
    "scores_bow = {}\n",
    "for classifier_name, classifier in classifiers_bow:\n",
    "    print('Training with {}'.format(classifier_name))\n",
    "    clf_bow[classifier_name] = [{}]*cv_folds\n",
    "    y_pred_bow[classifier_name] = [{}]*cv_folds\n",
    "    scores_bow[classifier_name] = [{}]*cv_folds\n",
    "    for fold in range(cv_folds):\n",
    "        print('Fold {}'.format(fold))\n",
    "        for label in labels:\n",
    "            clf_bow[classifier_name][fold][label] = classifier\n",
    "            clf_bow[classifier_name][fold][label].fit(X_train_features_bow[fold], y_train[fold][label])\n",
    "\n",
    "        y_pred_bow[classifier_name][fold] = pd.DataFrame()\n",
    "        for label in labels:\n",
    "            y_pred_bow[classifier_name][fold][label] = clf_bow[classifier_name][fold][label].predict_proba(X_test_features_bow[fold]).T[1]\n",
    "\n",
    "        scores_bow[classifier_name][fold] = calculate_score(y_test[fold], y_pred_bow[classifier_name][fold])\n",
    "    print('Column-wise log loss for {}: {} - {}'.format(classifier_name, scores_bow[classifier_name], np.mean(scores_bow[classifier_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
