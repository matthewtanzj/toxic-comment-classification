{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:39:42.262550Z",
     "start_time": "2017-12-24T15:39:42.251051Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textstat.textstat import textstat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.608054Z",
     "start_time": "2017-12-24T15:08:12.014055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = '../data/train.csv'\n",
    "test_file = '../data/test.csv'\n",
    "sample_submission_file = '../data/sample_submission.csv'\n",
    "\n",
    "train_all = pd.read_csv(train_file)\n",
    "test_for_submission = pd.read_csv(test_file)\n",
    "sample_submission = pd.read_csv(sample_submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.625054Z",
     "start_time": "2017-12-24T15:08:13.609055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_all, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count and check that the data is split such that the percentages of labels in train/test are roughly equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.629058Z",
     "start_time": "2017-12-24T15:08:13.626056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.658055Z",
     "start_time": "2017-12-24T15:08:13.630557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "        toxic: 7449 / 76680 (9.714%)\n",
      " severe_toxic: 783 / 76680 (1.021%)\n",
      "      obscene: 4153 / 76680 (5.416%)\n",
      "       threat: 247 / 76680 (0.322%)\n",
      "       insult: 3845 / 76680 (5.014%)\n",
      "identity_hate: 657 / 76680 (0.857%)\n",
      "test\n",
      "        toxic: 1788 / 19171 (9.327%)\n",
      " severe_toxic: 182 / 19171 (0.949%)\n",
      "      obscene: 956 / 19171 (4.987%)\n",
      "       threat: 58 / 19171 (0.303%)\n",
      "       insult: 920 / 19171 (4.799%)\n",
      "identity_hate: 157 / 19171 (0.819%)\n"
     ]
    }
   ],
   "source": [
    "def print_count_of_each_label(df):\n",
    "    for label in labels:\n",
    "        print('{}: {} / {} ({}%)'.format(label.rjust(len(labels[-1])),\n",
    "                                         df.loc[df[label] == 1].shape[0],\n",
    "                                         len(df),\n",
    "                                         np.round(df.loc[df[label] == 1].shape[0]/len(df)*100, 3)))\n",
    "\n",
    "print('train')\n",
    "print_count_of_each_label(train)\n",
    "print('test')\n",
    "print_count_of_each_label(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train/test into X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can use sklearn classifiers easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.668555Z",
     "start_time": "2017-12-24T15:08:13.659055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train[[\"comment_text\"]], train[labels]\n",
    "X_test, y_test = test[[\"comment_text\"]], test[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.679055Z",
     "start_time": "2017-12-24T15:08:13.669557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76680, 1) (76680, 6)\n",
      "(19171, 1) (19171, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate mean column-wise log loss of y_pred vs y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.694055Z",
     "start_time": "2017-12-24T15:08:13.680056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61761</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26528</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "61761      0             0        0       0       0              0\n",
       "6322       0             0        0       0       0              0\n",
       "26528      0             0        0       0       0              0\n",
       "47980      0             0        0       0       0              0\n",
       "90134      0             0        0       0       0              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.700557Z",
     "start_time": "2017-12-24T15:08:13.695055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_score(y_actual, y_pred):\n",
    "    return np.mean([log_loss(np.array(y_actual[label]),\n",
    "                             np.array([1.-np.array(y_pred[label]), np.array(y_pred[label])]).T) for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classification scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfect score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.726554Z",
     "start_time": "2017-12-24T15:08:13.701556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9920072216264108e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:13.783055Z",
     "start_time": "2017-12-24T15:08:13.760555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2193936235262668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([np.zeros(len(labels))] * len(X_test))\n",
    "y_pred_zeror = pd.DataFrame(data, columns=labels)\n",
    "calculate_score(y_test, y_pred_zeror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T12:28:47.459632Z",
     "start_time": "2017-12-24T12:28:47.455633Z"
    }
   },
   "source": [
    "## All 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:15.058071Z",
     "start_time": "2017-12-24T15:08:15.032073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69314718055994529"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([np.ones(len(labels))*0.5] * len(X_test))\n",
    "y_pred_half = pd.DataFrame(data, columns=labels)\n",
    "calculate_score(y_test, y_pred_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textstat features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:08:15.935151Z",
     "start_time": "2017-12-24T15:08:15.928652Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    features_df = pd.DataFrame()\n",
    "    features_df['comment_text_len'] = df['comment_text'].apply(len)\n",
    "    features_df['comment_text_lex_count'] = df['comment_text'].apply(textstat.lexicon_count)\n",
    "    features_df['comment_text_syl_count'] = df['comment_text'].apply(textstat.syllable_count)\n",
    "    features_df['comment_text_sent_count'] = df['comment_text'].apply(textstat.sentence_count)\n",
    "    features_df['comment_text_flesch_reading_ease'] = df['comment_text'].apply(textstat.flesch_reading_ease)\n",
    "    features_df['comment_text_flesch_kincaid_grade'] = df['comment_text'].apply(textstat.flesch_kincaid_grade)\n",
    "    \n",
    "    features_df['comment_text_syl_over_lex'] = features_df['comment_text_syl_count'] / features_df['comment_text_lex_count']\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:11:10.945027Z",
     "start_time": "2017-12-24T15:08:16.440592Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_features_textstat = extract_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:11:55.206585Z",
     "start_time": "2017-12-24T15:11:10.946028Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_features_textstat = extract_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through a bunch of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:25:04.132116Z",
     "start_time": "2017-12-24T15:25:04.127616Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (\"Nearest Neighbors\", KNeighborsClassifier(131)),\n",
    "    (\"Naive Bayes\", GaussianNB()),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(max_depth=5)),\n",
    "    (\"Random Forest\", RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)),\n",
    "    (\"Neural Net\", MLPClassifier(alpha=1)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier()),\n",
    "    (\"QDA\", QuadraticDiscriminantAnalysis()),\n",
    "    #     (\"Gaussian Process\", GaussianProcessClassifier(1.0 * RBF(1.0)))  # Memory error??? Even with 32GB ram???\n",
    "    #     (\"Linear SVM\", SVC(kernel=\"linear\", C=0.025)),                   # Slow as shit\n",
    "    #     (\"RBF SVM\", SVC(gamma=2, C=1))                                   # Slow as shit\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T15:25:27.824300Z",
     "start_time": "2017-12-24T15:25:04.134116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Nearest Neighbors\n",
      "Predicting with Nearest Neighbors\n",
      "Column-wise log loss for Nearest Neighbors: 0.4477744043060689\n",
      "Training with Naive Bayes\n",
      "Predicting with Naive Bayes\n",
      "Column-wise log loss for Naive Bayes: 0.5520901850154825\n",
      "Training with Decision Tree\n",
      "Predicting with Decision Tree\n",
      "Column-wise log loss for Decision Tree: 0.17642219076440394\n",
      "Training with Random Forest\n",
      "Predicting with Random Forest\n",
      "Column-wise log loss for Random Forest: 0.1660879190388692\n",
      "Training with Neural Net\n",
      "Predicting with Neural Net\n",
      "Column-wise log loss for Neural Net: 0.17423034114113337\n",
      "Training with AdaBoost\n",
      "Predicting with AdaBoost\n",
      "Column-wise log loss for AdaBoost: 0.6448197566728328\n",
      "Training with QDA\n",
      "Predicting with QDA\n",
      "Column-wise log loss for QDA: 0.42661147513758674\n"
     ]
    }
   ],
   "source": [
    "clf = {}\n",
    "y_pred = {}\n",
    "for classifier_name, classifier in classifiers:\n",
    "    print('Training with {}'.format(classifier_name))\n",
    "    clf[classifier_name] = {}\n",
    "    for label in labels:\n",
    "        clf[classifier_name][label] = classifier\n",
    "        clf[classifier_name][label].fit(X_train_features_textstat, y_train[label])\n",
    "    \n",
    "    print('Predicting with {}'.format(classifier_name))\n",
    "    y_pred[classifier_name] = pd.DataFrame()\n",
    "    for label in labels:\n",
    "        y_pred[classifier_name][label] = clf[classifier_name][label].predict_proba(X_test_features_textstat).T[1]\n",
    "    \n",
    "    score = calculate_score(y_test, y_pred[classifier_name])\n",
    "    print('Column-wise log loss for {}: {}'.format(classifier_name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
