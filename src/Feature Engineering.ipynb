{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "## May want to try count vectorizer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stating the path of the data files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path of the training / testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = \"../../data/data/train/train_cleaned.csv\"\n",
    "test_data_path = \"../../data/data/test/test_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path of the lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emo_lexicon_path = \"../../data/external dataset/NRC-AffectIntensity-Lexicon.txt\"\n",
    "block_terms_path = \"../../data/external dataset/Terms-To-Block.txt\"\n",
    "swear_words_path = \"../../data/external dataset/swearWords.txt\"\n",
    "google_bad_words_path = \"../../data/external dataset/google-bad-words.txt\"\n",
    "github_bad_words_path = \"../../data/external dataset/bad-words-github.txt\"\n",
    "bad_words_path = \"../../data/external dataset/bad-words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_tags(comment, tag):\n",
    "    length = len(comment.split(\" \"))\n",
    "    count = comment.lower().count(tag)\n",
    "    return float(count)/float(length), int(count > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_emotions(comment, emotion):\n",
    "    comment_array = comment.split(\" \")\n",
    "    length = len(comment_array)\n",
    "    count = len([emotion.get(x) for x in comment_array if emotion.get(x) is not None])\n",
    "    return float(count)/float(length), int(count > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_swear_words(comment, word_lst):\n",
    "#     comment = \" \" + comment + \" \"\n",
    "#     length = len(comment.split(\" \"))\n",
    "#     count = 0\n",
    "#     for word in word_lst:\n",
    "#         word = \" \" + word + \" \"\n",
    "#         if word in comment:\n",
    "#             comment = comment.replace(word, \"\")\n",
    "#             count += 1 \n",
    "    words = comment.split(\" \")\n",
    "    is_swear_word = [1 if word in word_lst else 0 for word in words]\n",
    "    total_swear_words = np.sum(is_swear_word)\n",
    "    return float(total_swear_words)/float(len(words)), int(total_swear_words>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_punc(comment):\n",
    "    counts = Counter(comment)\n",
    "    punc_dict = {key: occurences for key, occurences in counts.items() if key in punctuation}\n",
    "    punc_count = sum(punc_dict.values())\n",
    "    return punc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Emotion Lexicon class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmoLex: \n",
    "    \n",
    "    def __init__(self, emoPath):\n",
    "        self.emoPath = emoPath\n",
    "        self.emoLex = pd.read_csv(self.emoPath, sep = \"\\t\")\n",
    "        \n",
    "        self.anger = self.emoLex.loc[self.emoLex.loc[:, \"AffectDimension\"] == \"anger\", :]\n",
    "        self.fear = self.emoLex.loc[self.emoLex.loc[:, \"AffectDimension\"] == \"fear\", :]\n",
    "        self.joy = self.emoLex.loc[self.emoLex.loc[:, \"AffectDimension\"] == \"joy\", :]\n",
    "        self.sadness = self.emoLex.loc[self.emoLex.loc[:, \"AffectDimension\"] == \"sadness\", :]\n",
    "        \n",
    "        anger_dict = {}\n",
    "        for i in range(0, self.anger.shape[0]):\n",
    "            word = self.anger.iloc[i, :].term\n",
    "            score = self.anger.iloc[i, :].score\n",
    "            anger_dict[word] = score\n",
    "            \n",
    "        fear_dict = {}\n",
    "        for i in range(0, self.fear.shape[0]):\n",
    "            word = self.fear.iloc[i, :].term\n",
    "            score = self.fear.iloc[i, :].score\n",
    "            fear_dict[word] = score\n",
    "            \n",
    "        joy_dict = {}\n",
    "        for i in range(0, self.joy.shape[0]):\n",
    "            word = self.joy.iloc[i, :].term\n",
    "            score = self.joy.iloc[i, :].score\n",
    "            joy_dict[word] = score\n",
    "            \n",
    "        sadness_dict = {}\n",
    "        for i in range(0, self.sadness.shape[0]):\n",
    "            word = self.sadness.iloc[i, :].term\n",
    "            score = self.sadness.iloc[i, :].score\n",
    "            sadness_dict[word] = score\n",
    "            \n",
    "        self.anger_dict = anger_dict\n",
    "        self.fear_dict = fear_dict\n",
    "        self.joy_dict = joy_dict\n",
    "        self.sadness_dict = sadness_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the vulgarities class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vulgarities:\n",
    "    \n",
    "    def __init__(self, block_terms_path, swear_words_path, \n",
    "                 google_bad_words_path, github_bad_words_path, bad_words_path):\n",
    "        \n",
    "        self.block_terms_path = block_terms_path\n",
    "        self.swear_words_path = swear_words_path\n",
    "        self.google_bad_words_path = google_bad_words_path\n",
    "        self.github_bad_words_path = github_bad_words_path\n",
    "        self.bad_words_path = bad_words_path\n",
    "        \n",
    "#         self.block_terms_list = list(pd.read_csv(self.block_terms_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "#         self.swear_words_list = list(pd.read_csv(self.swear_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "#         self.google_bad_words_list = list(pd.read_csv(self.google_bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "#         self.github_bad_words_list = list(pd.read_csv(self.github_bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "#         self.bad_words_list = list(pd.read_csv(self.bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        \n",
    "        self.block_terms_list = set(pd.read_csv(self.block_terms_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        self.swear_words_list = set(pd.read_csv(self.swear_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        self.google_bad_words_list = set(pd.read_csv(self.google_bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        self.github_bad_words_list = set(pd.read_csv(self.github_bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        self.bad_words_list = set(pd.read_csv(self.bad_words_path, header = None, names= [\"words\"]).loc[:, \"words\"])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self, path, type_):\n",
    "        self.path = path\n",
    "        self.df = pd.read_csv(path)\n",
    "    \n",
    "    def addBOWFeatures(self, vectorizer):\n",
    "        sparse_matrix = vectorizer.transform(self.df.loc[:, \"comment_text\"])\n",
    "        bow_df = pd.DataFrame(np.array(sparse_matrix.todense()))\n",
    "        self.bow = pd.concat([self.df.loc[:, \"id\"], bow_df], axis = 1)\n",
    "    \n",
    "    def addTagFeatures(self):\n",
    "        self.df.loc[:, \"pres_links\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_tags(x, \"<link>\")[1])\n",
    "        self.df.loc[:, \"pres_image\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_tags(x, \"<image>\")[1])\n",
    "        self.df.loc[:, \"pres_user\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_tags(x, \"<user>\")[1])\n",
    "        self.df.loc[:, \"pres_date\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_tags(x, \"(utc)\")[1])\n",
    "        \n",
    "    def addEmotionFeatures(self, emotion):\n",
    "        self.df.loc[:, \"pres_anger\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_emotions(x, emotion.anger_dict)[1])\n",
    "        self.df.loc[:, \"pres_fear\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_emotions(x, emotion.fear_dict)[1])\n",
    "        self.df.loc[:, \"pres_joy\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_emotions(x, emotion.joy_dict)[1])\n",
    "        self.df.loc[:, \"pres_sadness\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_emotions(x, emotion.sadness_dict)[1])\n",
    "        \n",
    "    def addVulgaritiesFeatures(self, terms):\n",
    "        self.df.loc[:, \"pres_block_terms\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_swear_words(x, terms.block_terms_list)[1])\n",
    "        self.df.loc[:, \"pres_swear_words\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_swear_words(x, terms.swear_words_list)[1])\n",
    "        self.df.loc[:, \"pres_google_bad_words\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_swear_words(x, terms.google_bad_words_list)[1])\n",
    "        self.df.loc[:, \"pres_github_bad_words\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_swear_words(x, terms.github_bad_words_list)[1])\n",
    "        self.df.loc[:, \"pres_bad_words\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: check_swear_words(x, terms.bad_words_list)[1])\n",
    "    \n",
    "    def addPunctuationCount(self):\n",
    "        self.df.loc[:, \"punc_count\"] = self.df.loc[:, \"comment_text\"].apply(lambda x: count_punc(x))\n",
    "        self.df.loc[:, \"punc_count_normed\"] = self.df.apply(lambda x: x[\"punc_count\"] / len(x[\"comment_text\"]) , axis=1)\n",
    "    \n",
    "    def writeFeatures(self, path_manual_features, path_bow_features):\n",
    "        self.bow.to_csv(path_bow_features, index = None)\n",
    "        self.df.to_csv(path_manual_features, index = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_data, test_data, vectorizer):\n",
    "    \n",
    "    vulgarities_lexicon = Vulgarities(block_terms_path, swear_words_path, google_bad_words_path, github_bad_words_path, bad_words_path)\n",
    "    emo_lexicon = EmoLex(emo_lexicon_path)\n",
    "    \n",
    "    print(\"adding features for training data\")\n",
    "    train_data.addBOWFeatures(vectorizer)\n",
    "    train_data.addTagFeatures()\n",
    "    train_data.addVulgaritiesFeatures(vulgarities_lexicon)\n",
    "    train_data.addEmotionFeatures(emo_lexicon)\n",
    "    train_data.addPunctuationCount()\n",
    "    train_data.writeFeatures(\"../../data/data/train/train_data_manual.csv\", \"../data/data/train/train_data_bow.csv\")\n",
    "    print(\"done adding features for training data\")\n",
    "    \n",
    "    print(\"adding features for testing data\")\n",
    "    test_data.addBOWFeatures(vectorizer)\n",
    "    test_data.addTagFeatures()\n",
    "    test_data.addVulgaritiesFeatures(vulgarities_lexicon)\n",
    "    test_data.addEmotionFeatures(emo_lexicon)\n",
    "    test_data.addPunctuationCount()\n",
    "    test_data.writeFeatures(\"../../data/data/test/test_data_manual.csv\", \"../data/data/test/test_data_bow.csv\")\n",
    "    print(\"done adding features for testing data\")\n",
    "    \n",
    "    return train_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding features for training data\n",
      "done adding features for training data\n",
      "adding features for testing data\n",
      "done adding features for testing data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train_data = Data(train_data_path, \"train\")\n",
    "    test_data = Data(test_data_path, \"test\")\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df= 0.05, max_df = 0.75, lowercase=True, ngram_range= (1,2)) # play around with the ngram\n",
    "    comments = list(train_data.df.loc[:, \"comment_text\"]) + list(test_data.df.loc[:, \"comment_text\"])\n",
    "    vectorizer.fit(comments)\n",
    "    \n",
    "    train_data, test_data = main(train_data, test_data, vectorizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
